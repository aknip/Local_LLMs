{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Local_LLMs/blob/main/OpenAI_Whisper_local_YouTube_Download_and_Transcribe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI - Local whisper: Demo YouTube mp3 download and transcription\n",
        "\n",
        "- Demovideo (8 min): https://www.youtube.com/watch?v=Rbl7qmTH6b8\n",
        "\n",
        "- https://github.com/openai/whisper"
      ],
      "metadata": {
        "id": "rnhhqqZAM4wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "id": "TtHK2NTSM6_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mQxpGx2dA2lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "id": "KSDotJV-NESV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp -x --audio-format mp3 https://www.youtube.com/watch?v=Rbl7qmTH6b8 -o test.mp3"
      ],
      "metadata": {
        "id": "7W30YpXSNEX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model_size = \"large-v3\"\n",
        "\n",
        "model = whisper.load_model(model_size)\n",
        "result = model.transcribe(\"test.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HXQ9jluNEag",
        "outputId": "06602c75-2ea7-4dd9-e37e-27e4f0d26f61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:35<00:00, 87.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " We have a lot more information about what went down yesterday with Sam Altman getting fired from OpenAI. So let me give you a bunch of updates, but of course, we don't know everything yet. So shortly after the board announced that Sam Altman was getting fired, Sam Altman posted on X, I loved my time at OpenAI. It was transformative for me personally and hopefully the world a little bit. Absolutely. Most of all, I loved working with such talented people. We'll have more to say about what's next later. Sam Altman is one of the best operators and founders and technologists in general of our generation. And for him to unceremoniously get fired from the company that he's put his blood, sweat, and tears into over the years, it hurts my heart to hear as a former founder myself. And not only that, he was seemingly betrayed by two of his close colleagues. And ultimately, the board is the one that fired him. And funny enough, the board probably spends only one to two hours a month working on OpenAI. And Sam Altman probably spends... 16 hours a day on it. So it's really heartbreaking to see this. And I was following Kara Swisher all night because she was reporting the news in near real time. And it seems like a lot of what she was saying was really accurate. And what seems to happen is Ilya Sutskovor and Mira Murady had a split with Sam Altman and Greg Brockman. But why? Why did they do this? That's the important question. From all the reporting I read, it seems to relate to the fact that Sam Altman and Greg Brockman wanted to move really, fast. They wanted to release technology as quickly as they could. And they wanted to make a lot of money doing it. But OpenAI has this weird structure where they're a non-profit company. But then they created this separate entity that could make profit, but it was still owned by the non-profit. And nobody on the board really had a financial incentive aligned with the company. They don't have shares. And neither did Sam Altman, frankly. So it's really just an odd structure for one of the most influential companies of our generation. And Ilya, Mira, and the board... seem to just get really nervous. And Sam Altman seemed to be really headstrong and thought he could just make all the decisions. But ultimately, the board makes the decisions. The board can hire and fire CEOs. That is what they do. So let's take a look at what Kara Swisher said. So it looks like Ilya Sutskovor said a few things about the situation. Let's read it. You can call it this way, Sutskovor said about the coup allegations. Of course, a lot of people are calling it a coup. And I can understand why you would choose this word. But I disagree with this. This was the board doing its duty to the mission of the non-profit. Which is the board doing its duty to the mission of the non-profit. Which is the board doing its duty to the mission of the non-profit. Which is to make sure that OpenAI builds AGI that benefits all of humanity. When Sutskovor was asked whether these backroom removals are a good way to govern the most important company in the world, he answered, I mean, fair. I agree that there is not an ideal element to it. 100%. And here's the crazy part. Basically, nobody knew. Kara Swisher reported that Sam Altman found out 30 minutes in advance. Greg Brockman, 5 minutes in advance. And Greg Brockman was the chair of the board. So they really made a move on him. And Microsoft, who owns about 50%, was told just before it all went down. So it's really just a handful of people who made this incredible move. And yeah, she used a clown in a car because yes, this is a clown car right now. And Kara also reported at 8.32 PM last night, more of the board members who voted against Altman felt he was manipulative and headstrong and wanted to do what he wanted to do. That sounds like the typical SV Silicon Valley CEO to me, but this might not be the typical SV company. And yeah, these are extremely aggressive, extremely bright people who are advancing the most important technology of our time. But the structure of open AI is non-typical for Silicon Valley. And then she follows up with, would be eager to hear the actual specifics of their concerns and also evidence that they tried to inform him if they had problems and gave him a chance to respond and change. If not, looks clottish. So that is a really good point. Specifically in the blog post by the board, they said that Sam Altman was not consistently candid with the board. That means he was lying to the board. And so they're probably going to have to put out evidence soon. Otherwise, they're going to look really foolish. Then at 8.42 PM last night, Greg Brockman put out his statement. Sam and I are shocked and saddened by what the board did today. So Sam and Greg are completely aligned with this. And I wouldn't be surprised if they announced a new company as soon as Monday. Let us first say thank you to all the incredible people who we have worked with at open AI. Our customers, our investors, and all of those who have been reaching out. We too are still trying to figure out exactly what happened. Here is what we know. It's really shocking how this went down and almost nobody knew what was going on. History might see this as one of the worst board decisions of all time. Last night, Sam got a text from Ilya asking to talk at noon Friday. Sam joined the Google Meet and the whole board, except Greg, was there. Now, it's interesting that he says except Greg when he's talking about himself, but fine. Ilya told Sam he was being fired, and that the news was going out very soon. At 1219, Greg got a text from Ilya asking for a quick call. At 1223, Ilya sent a Google Meet link. Greg was told that he's being removed from the board, but was vital to the company and would retain his role, and that Sam had been fired. Around the same time, open AI published a blog post. The fact that the board thought that they could fire Sam Altman, demote Greg Brockman, but still keep him at the company seems absurd to me. I have no idea what they were thinking. As far as we know, the management team was made, and beware of this shortly after, other than Mira, who found out the night prior. So it's interesting. She knew, but she only found out the night prior. So it looks like she wasn't involved in the actual decision, but she definitely sided with the board's decision on this. The outpouring of support has been really nice. Thank you, but please don't spend any time being concerned. We will be fine. Greater things coming soon. Of course, these are two of the greatest founders of all time, and they're going to be totally fine. And the amount of posts from founders that I've read about Sam Altman helping them throughout his career and their career has been really amazing. Sam Altman is well liked, well respected through Silicon Valley and through the entire world of technology. Sam Altman at 9 0 5 p.m. Put out a post. I love you all. Today was a weird experience in many ways, but one unexpected one is that it has been sort of like reading your own eulogy while you're still alive. The outpouring of love is awesome. One takeaway, go tell your friends how great you think they are. I agree. And then I just want to show this reply to that. Tweet run it back brother for praying for exits. This is a reference to a curb your enthusiasm episode where Larry David builds a coffee shop next to a coffee shop that did him wrong. And it was a spite coffee shop. So he built it completely out of spite. And this is just such an incredible reference and Sam Altman needs to go build an AI company purely out of spite. And then here's the weird one 9 32 p.m. If I start going off the open AI board should go after me for the full value of my shares. Now, this is a complete troll because Sam Altman has already mentioned in the past. He basically has no financial incentive in open AI. He has no shares or the shares. He does have are worth very little to nothing. So he's basically like, all right, I'm out now. I can say whatever I want because you literally can't take any of my shares back. They're not worth anything. And then late last night Killian has reported at 1245 a.m. More senior departures from open AI tonight GPT for lead director of research. Jacob Hachaki, head of AI risk Alexander Madri open-source baselines researcher, Sisman Sayed or and Sam Altman Greg Brockman and that's just day one. And yeah, if Sam Altman is truly liked and respected within open AI as a lot of people are reporting and that is clear in the broader industry. A lot of people are going to follow him. So still a lot going on still a lot of information coming out, but that's what we know definitively for now. If you liked this video, please consider giving a like and subscribe and I'll see you in the next one.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments = result[\"segments\"]\n",
        "\n",
        "for segment in segments:\n",
        "    print(\"[%.2fs -> %.2fs] %s\" % (segment['start'], segment['end'], segment['text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcFZkgkSNEc1",
        "outputId": "6a98fe2e-b6f6-4ff6-9311-8024a3d861cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00s -> 5.02s]  We have a lot more information about what went down yesterday with Sam Altman getting fired from OpenAI.\n",
            "[5.32s -> 9.12s]  So let me give you a bunch of updates, but of course, we don't know everything yet.\n",
            "[9.12s -> 14.40s]  So shortly after the board announced that Sam Altman was getting fired, Sam Altman posted on X,\n",
            "[14.54s -> 19.40s]  I loved my time at OpenAI. It was transformative for me personally and hopefully the world a little bit.\n",
            "[19.54s -> 22.66s]  Absolutely. Most of all, I loved working with such talented people.\n",
            "[22.78s -> 25.22s]  We'll have more to say about what's next later.\n",
            "[25.22s -> 31.66s]  Sam Altman is one of the best operators and founders and technologists in general of our generation.\n",
            "[31.94s -> 38.32s]  And for him to unceremoniously get fired from the company that he's put his blood, sweat, and tears into over the years,\n",
            "[38.42s -> 41.12s]  it hurts my heart to hear as a former founder myself.\n",
            "[41.28s -> 44.84s]  And not only that, he was seemingly betrayed by two of his close colleagues.\n",
            "[45.04s -> 48.10s]  And ultimately, the board is the one that fired him.\n",
            "[48.24s -> 53.48s]  And funny enough, the board probably spends only one to two hours a month working on OpenAI.\n",
            "[53.48s -> 54.98s]  And Sam Altman probably spends...\n",
            "[55.22s -> 57.04s]  16 hours a day on it.\n",
            "[57.12s -> 59.42s]  So it's really heartbreaking to see this.\n",
            "[59.58s -> 64.68s]  And I was following Kara Swisher all night because she was reporting the news in near real time.\n",
            "[64.90s -> 67.80s]  And it seems like a lot of what she was saying was really accurate.\n",
            "[68.02s -> 74.94s]  And what seems to happen is Ilya Sutskovor and Mira Murady had a split with Sam Altman and Greg Brockman.\n",
            "[75.08s -> 78.02s]  But why? Why did they do this? That's the important question.\n",
            "[78.02s -> 85.18s]  From all the reporting I read, it seems to relate to the fact that Sam Altman and Greg Brockman wanted to move really,\n",
            "[85.32s -> 88.54s]  fast. They wanted to release technology as quickly as they could.\n",
            "[88.64s -> 90.74s]  And they wanted to make a lot of money doing it.\n",
            "[90.82s -> 95.14s]  But OpenAI has this weird structure where they're a non-profit company.\n",
            "[95.30s -> 100.46s]  But then they created this separate entity that could make profit, but it was still owned by the non-profit.\n",
            "[100.70s -> 104.74s]  And nobody on the board really had a financial incentive aligned with the company.\n",
            "[104.86s -> 106.02s]  They don't have shares.\n",
            "[106.26s -> 108.28s]  And neither did Sam Altman, frankly.\n",
            "[108.28s -> 113.12s]  So it's really just an odd structure for one of the most influential companies of our generation.\n",
            "[113.60s -> 115.18s]  And Ilya, Mira, and the board...\n",
            "[115.34s -> 117.34s]  seem to just get really nervous.\n",
            "[117.34s -> 121.54s]  And Sam Altman seemed to be really headstrong and thought he could just make all the decisions.\n",
            "[121.54s -> 123.90s]  But ultimately, the board makes the decisions.\n",
            "[123.90s -> 125.90s]  The board can hire and fire CEOs.\n",
            "[125.90s -> 126.94s]  That is what they do.\n",
            "[126.94s -> 128.82s]  So let's take a look at what Kara Swisher said.\n",
            "[128.82s -> 131.78s]  So it looks like Ilya Sutskovor said a few things about the situation.\n",
            "[131.78s -> 132.44s]  Let's read it.\n",
            "[132.44s -> 135.38s]  You can call it this way, Sutskovor said about the coup allegations.\n",
            "[135.38s -> 137.48s]  Of course, a lot of people are calling it a coup.\n",
            "[137.48s -> 139.68s]  And I can understand why you would choose this word.\n",
            "[139.68s -> 141.06s]  But I disagree with this.\n",
            "[141.06s -> 145.02s]  This was the board doing its duty to the mission of the non-profit.\n",
            "[145.02s -> 145.18s]  Which is the board doing its duty to the mission of the non-profit.\n",
            "[145.18s -> 145.20s]  Which is the board doing its duty to the mission of the non-profit.\n",
            "[145.22s -> 148.82s]  Which is to make sure that OpenAI builds AGI that benefits all of humanity.\n",
            "[148.82s -> 154.02s]  When Sutskovor was asked whether these backroom removals are a good way to govern the most important company in the world,\n",
            "[154.02s -> 154.62s]  he answered,\n",
            "[154.62s -> 155.74s]  I mean, fair.\n",
            "[155.74s -> 158.50s]  I agree that there is not an ideal element to it.\n",
            "[158.50s -> 159.42s]  100%.\n",
            "[159.42s -> 160.98s]  And here's the crazy part.\n",
            "[160.98s -> 162.78s]  Basically, nobody knew.\n",
            "[162.78s -> 166.70s]  Kara Swisher reported that Sam Altman found out 30 minutes in advance.\n",
            "[166.70s -> 169.34s]  Greg Brockman, 5 minutes in advance.\n",
            "[169.34s -> 172.18s]  And Greg Brockman was the chair of the board.\n",
            "[172.18s -> 175.02s]  So they really made a move on him.\n",
            "[175.02s -> 179.62s]  And Microsoft, who owns about 50%, was told just before it all went down.\n",
            "[179.62s -> 183.62s]  So it's really just a handful of people who made this incredible move.\n",
            "[183.62s -> 188.14s]  And yeah, she used a clown in a car because yes, this is a clown car right now.\n",
            "[188.14s -> 191.92s]  And Kara also reported at 8.32 PM last night,\n",
            "[191.92s -> 198.02s]  more of the board members who voted against Altman felt he was manipulative and headstrong and wanted to do what he wanted to do.\n",
            "[198.02s -> 204.22s]  That sounds like the typical SV Silicon Valley CEO to me, but this might not be the typical SV company.\n",
            "[204.22s -> 204.82s]  And yeah,\n",
            "[204.82s -> 213.42s]  these are extremely aggressive, extremely bright people who are advancing the most important technology of our time.\n",
            "[213.42s -> 217.82s]  But the structure of open AI is non-typical for Silicon Valley.\n",
            "[217.82s -> 219.12s]  And then she follows up with,\n",
            "[219.12s -> 227.72s]  would be eager to hear the actual specifics of their concerns and also evidence that they tried to inform him if they had problems and gave him a chance to respond and change.\n",
            "[227.72s -> 229.32s]  If not, looks clottish.\n",
            "[229.32s -> 231.72s]  So that is a really good point.\n",
            "[231.72s -> 234.02s]  Specifically in the blog post by the board,\n",
            "[234.02s -> 237.32s]  they said that Sam Altman was not consistently candid with the board.\n",
            "[237.32s -> 239.22s]  That means he was lying to the board.\n",
            "[239.22s -> 242.12s]  And so they're probably going to have to put out evidence soon.\n",
            "[242.12s -> 244.42s]  Otherwise, they're going to look really foolish.\n",
            "[244.42s -> 249.42s]  Then at 8.42 PM last night, Greg Brockman put out his statement.\n",
            "[249.42s -> 252.52s]  Sam and I are shocked and saddened by what the board did today.\n",
            "[252.52s -> 255.32s]  So Sam and Greg are completely aligned with this.\n",
            "[255.32s -> 258.92s]  And I wouldn't be surprised if they announced a new company as soon as Monday.\n",
            "[258.92s -> 262.82s]  Let us first say thank you to all the incredible people who we have worked with at open AI.\n",
            "[262.82s -> 264.02s]  Our customers, our investors,\n",
            "[264.02s -> 265.82s]  and all of those who have been reaching out.\n",
            "[265.82s -> 268.22s]  We too are still trying to figure out exactly what happened.\n",
            "[268.22s -> 269.22s]  Here is what we know.\n",
            "[269.22s -> 274.02s]  It's really shocking how this went down and almost nobody knew what was going on.\n",
            "[274.02s -> 278.82s]  History might see this as one of the worst board decisions of all time.\n",
            "[278.82s -> 282.42s]  Last night, Sam got a text from Ilya asking to talk at noon Friday.\n",
            "[282.42s -> 284.82s]  Sam joined the Google Meet and the whole board,\n",
            "[284.82s -> 286.82s]  except Greg, was there.\n",
            "[286.82s -> 290.22s]  Now, it's interesting that he says except Greg when he's talking about himself,\n",
            "[290.22s -> 291.12s]  but fine.\n",
            "[291.12s -> 293.42s]  Ilya told Sam he was being fired,\n",
            "[293.42s -> 295.22s]  and that the news was going out very soon.\n",
            "[295.22s -> 299.02s]  At 1219, Greg got a text from Ilya asking for a quick call.\n",
            "[299.02s -> 302.22s]  At 1223, Ilya sent a Google Meet link.\n",
            "[302.22s -> 304.12s]  Greg was told that he's being removed from the board,\n",
            "[304.12s -> 306.92s]  but was vital to the company and would retain his role,\n",
            "[306.92s -> 308.42s]  and that Sam had been fired.\n",
            "[308.42s -> 310.72s]  Around the same time, open AI published a blog post.\n",
            "[310.72s -> 314.42s]  The fact that the board thought that they could fire Sam Altman,\n",
            "[314.42s -> 315.92s]  demote Greg Brockman,\n",
            "[315.92s -> 319.42s]  but still keep him at the company seems absurd to me.\n",
            "[319.42s -> 321.42s]  I have no idea what they were thinking.\n",
            "[321.42s -> 322.12s]  As far as we know,\n",
            "[322.12s -> 323.22s]  the management team was made,\n",
            "[323.22s -> 324.92s]  and beware of this shortly after,\n",
            "[324.92s -> 327.52s]  other than Mira, who found out the night prior.\n",
            "[327.52s -> 328.62s]  So it's interesting.\n",
            "[328.62s -> 332.02s]  She knew, but she only found out the night prior.\n",
            "[332.02s -> 335.42s]  So it looks like she wasn't involved in the actual decision,\n",
            "[335.42s -> 338.62s]  but she definitely sided with the board's decision on this.\n",
            "[338.62s -> 340.42s]  The outpouring of support has been really nice.\n",
            "[340.42s -> 342.42s]  Thank you, but please don't spend any time being concerned.\n",
            "[342.42s -> 343.12s]  We will be fine.\n",
            "[343.12s -> 344.22s]  Greater things coming soon.\n",
            "[344.22s -> 346.92s]  Of course, these are two of the greatest founders of all time,\n",
            "[346.92s -> 348.72s]  and they're going to be totally fine.\n",
            "[348.72s -> 353.02s]  And the amount of posts from founders that I've read about Sam Altman helping them\n",
            "[353.02s -> 356.92s]  throughout his career and their career has been really amazing.\n",
            "[356.92s -> 358.92s]  Sam Altman is well liked,\n",
            "[358.92s -> 363.62s]  well respected through Silicon Valley and through the entire world of technology.\n",
            "[363.62s -> 365.92s]  Sam Altman at 9 0 5 p.m.\n",
            "[365.92s -> 366.92s]  Put out a post.\n",
            "[366.92s -> 367.82s]  I love you all.\n",
            "[367.82s -> 369.72s]  Today was a weird experience in many ways,\n",
            "[369.72s -> 374.12s]  but one unexpected one is that it has been sort of like reading your own eulogy\n",
            "[374.12s -> 375.12s]  while you're still alive.\n",
            "[375.12s -> 377.02s]  The outpouring of love is awesome.\n",
            "[377.02s -> 380.02s]  One takeaway, go tell your friends how great you think they are.\n",
            "[380.02s -> 380.72s]  I agree.\n",
            "[380.72s -> 383.02s]  And then I just want to show this reply to that.\n",
            "[383.02s -> 385.72s]  Tweet run it back brother for praying for exits.\n",
            "[385.72s -> 393.62s]  This is a reference to a curb your enthusiasm episode where Larry David builds a coffee shop next to a coffee shop that did him wrong.\n",
            "[393.62s -> 395.02s]  And it was a spite coffee shop.\n",
            "[395.02s -> 396.72s]  So he built it completely out of spite.\n",
            "[396.72s -> 402.82s]  And this is just such an incredible reference and Sam Altman needs to go build an AI company purely out of spite.\n",
            "[402.82s -> 406.52s]  And then here's the weird one 9 32 p.m.\n",
            "[406.52s -> 411.82s]  If I start going off the open AI board should go after me for the full value of my shares.\n",
            "[411.82s -> 412.02s]  Now,\n",
            "[412.02s -> 412.62s]  this is a\n",
            "[413.02s -> 416.82s]  complete troll because Sam Altman has already mentioned in the past.\n",
            "[416.82s -> 419.82s]  He basically has no financial incentive in open AI.\n",
            "[419.82s -> 421.42s]  He has no shares or the shares.\n",
            "[421.42s -> 424.12s]  He does have are worth very little to nothing.\n",
            "[424.12s -> 425.22s]  So he's basically like,\n",
            "[425.22s -> 425.82s]  all right,\n",
            "[425.82s -> 426.72s]  I'm out now.\n",
            "[426.72s -> 430.42s]  I can say whatever I want because you literally can't take any of my shares back.\n",
            "[430.42s -> 431.52s]  They're not worth anything.\n",
            "[431.52s -> 436.12s]  And then late last night Killian has reported at 1245 a.m.\n",
            "[436.12s -> 441.42s]  More senior departures from open AI tonight GPT for lead director of research.\n",
            "[441.42s -> 442.82s]  Jacob Hachaki,\n",
            "[442.82s -> 447.32s]  head of AI risk Alexander Madri open-source baselines researcher,\n",
            "[447.32s -> 451.62s]  Sisman Sayed or and Sam Altman Greg Brockman and that's just day one.\n",
            "[451.62s -> 452.02s]  And yeah,\n",
            "[452.02s -> 460.72s]  if Sam Altman is truly liked and respected within open AI as a lot of people are reporting and that is clear in the broader industry.\n",
            "[460.72s -> 462.52s]  A lot of people are going to follow him.\n",
            "[462.52s -> 465.82s]  So still a lot going on still a lot of information coming out,\n",
            "[465.82s -> 468.02s]  but that's what we know definitively for now.\n",
            "[468.02s -> 468.92s]  If you liked this video,\n",
            "[468.92s -> 472.02s]  please consider giving a like and subscribe and I'll see you in the next one.\n"
          ]
        }
      ]
    }
  ]
}