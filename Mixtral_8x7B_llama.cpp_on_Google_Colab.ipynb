{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Local_LLMs/blob/main/Mixtral_8x7B_llama.cpp_on_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Approach: Mixtral-8x7B-Instruct via llama.cpp-python\n",
        "\n",
        "Speed Google T4:\n",
        "- mixtral-8x7b: 4 token / sec\n",
        "- mistral-7b: 12 token /sec\n",
        "\n",
        "Context size (sum of input and output):\n",
        "- default when calling llm =Llama(...) without n_ctx parameter: 512 token\n",
        "- max input size is 50% of n_ctx\n",
        "- see https://github.com/abetlen/llama-cpp-python#adjusting-the-context-window\n",
        "\n",
        "Max context size for models (to be checked!)\n",
        "- mixtral-8x7b: 2048 token? 32768 for not quantizized version\n",
        "- mistral-7b: 2048 token? 32768 for not quantizized version\n",
        "\n",
        "Context checks done for mixtral-8x7b:\n",
        "- n_ctx = 2048 OK\n",
        "- n_ctx = 4096 OK\n",
        "\n",
        "\n",
        "Source:\n",
        "https://koji-kanao.medium.com/run-mistral-7b-on-google-colab-less-than-20-lines-883c483df998"
      ],
      "metadata": {
        "id": "qNPPvNJXgPP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'mixtral-8x7b-instruct-v0.1.Q2_K'\n",
        "#model = 'openhermes-2-mistral-7b.Q5_K_M'\n",
        "\n",
        "if model == 'mixtral-8x7b-instruct-v0.1.Q2_K':\n",
        "\t!wget https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\n",
        "elif model == 'openhermes-2-mistral-7b.Q5_K_M':\n",
        "\t!wget https://huggingface.co/TheBloke/OpenHermes-2-Mistral-7B-GGUF/resolve/main/openhermes-2-mistral-7b.Q5_K_M.gguf\n",
        "elif model == 'dolphin-2.6-mixtral-8x7b.Q2_K':\n",
        "\t!wget https://huggingface.co/TheBloke/dolphin-2.6-mixtral-8x7b-GGUF/resolve/main/dolphin-2.6-mixtral-8x7b.Q2_K.gguf\n",
        "elif model == 'mistral-7b-instruct-v0.2.Q8':\n",
        "\t!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q8_0.gguf\n",
        "elif model == 'dolphin-2.2.1-mistral-7b.Q8':\n",
        "\t!wget https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF/resolve/main/dolphin-2.2.1-mistral-7b.Q8_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMjpE7rsjXCb",
        "outputId": "584010ae-a3b8-44eb-839b-f992cb4ea94f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-04 14:15:51--  https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.4, 18.172.134.124, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/ac/ba/acba0635d39a127379c2c6ae1cefacc586bf413e8b044c5ca82daade27d7d503/d54b4f4ec06dbae558d25b2d1542417cdf9547907342db85eecd05b6e96e88f8?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27mixtral-8x7b-instruct-v0.1.Q2_K.gguf%3B+filename%3D%22mixtral-8x7b-instruct-v0.1.Q2_K.gguf%22%3B&Expires=1704636951&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNDYzNjk1MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2FjL2JhL2FjYmEwNjM1ZDM5YTEyNzM3OWMyYzZhZTFjZWZhY2M1ODZiZjQxM2U4YjA0NGM1Y2E4MmRhYWRlMjdkN2Q1MDMvZDU0YjRmNGVjMDZkYmFlNTU4ZDI1YjJkMTU0MjQxN2NkZjk1NDc5MDczNDJkYjg1ZWVjZDA1YjZlOTZlODhmOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=jGGnWv25QDX4HhvEQFvMpf4ymF%7EmwD4J-g-EsXnJlD3D7hjV2mhqzgU4QD26uUcsvV8%7E7DdobQRGPQk2W3Wx0szHEh2tn6gAKqvqhyVh06LAUwiiEj4u-gkUL3bh3v0BQjQj85j9Y1v%7EVueP5B1VqWzFU8ezCgIvoQBwcKkFolaifDXdZI1vXrC-NKbdSI%7E2MENrKVkiKqjsrDoZRLr4jYPMWoZH6idAaFui%7EKrhcxt9CcZLv1cgJdNRUVZLbZkiXi3ftsC%7E%7E9FKEkM2t8Ln%7EoENDvhwawz0pdjqwSJpwPKqradSeJuDim88iSn1%7E5%7EewIcwAKdKXUqtlAdVf1uorg__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
            "--2024-01-04 14:15:52--  https://cdn-lfs-us-1.huggingface.co/repos/ac/ba/acba0635d39a127379c2c6ae1cefacc586bf413e8b044c5ca82daade27d7d503/d54b4f4ec06dbae558d25b2d1542417cdf9547907342db85eecd05b6e96e88f8?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27mixtral-8x7b-instruct-v0.1.Q2_K.gguf%3B+filename%3D%22mixtral-8x7b-instruct-v0.1.Q2_K.gguf%22%3B&Expires=1704636951&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNDYzNjk1MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2FjL2JhL2FjYmEwNjM1ZDM5YTEyNzM3OWMyYzZhZTFjZWZhY2M1ODZiZjQxM2U4YjA0NGM1Y2E4MmRhYWRlMjdkN2Q1MDMvZDU0YjRmNGVjMDZkYmFlNTU4ZDI1YjJkMTU0MjQxN2NkZjk1NDc5MDczNDJkYjg1ZWVjZDA1YjZlOTZlODhmOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=jGGnWv25QDX4HhvEQFvMpf4ymF%7EmwD4J-g-EsXnJlD3D7hjV2mhqzgU4QD26uUcsvV8%7E7DdobQRGPQk2W3Wx0szHEh2tn6gAKqvqhyVh06LAUwiiEj4u-gkUL3bh3v0BQjQj85j9Y1v%7EVueP5B1VqWzFU8ezCgIvoQBwcKkFolaifDXdZI1vXrC-NKbdSI%7E2MENrKVkiKqjsrDoZRLr4jYPMWoZH6idAaFui%7EKrhcxt9CcZLv1cgJdNRUVZLbZkiXi3ftsC%7E%7E9FKEkM2t8Ln%7EoENDvhwawz0pdjqwSJpwPKqradSeJuDim88iSn1%7E5%7EewIcwAKdKXUqtlAdVf1uorg__&Key-Pair-Id=KCD77M1F0VK2B\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 108.156.107.49, 108.156.107.44, 108.156.107.80, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|108.156.107.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15644035008 (15G) [binary/octet-stream]\n",
            "Saving to: ‘mixtral-8x7b-instruct-v0.1.Q2_K.gguf’\n",
            "\n",
            "mixtral-8x7b-instru 100%[===================>]  14.57G   245MB/s    in 87s     \n",
            "\n",
            "2024-01-04 14:17:19 (171 MB/s) - ‘mixtral-8x7b-instruct-v0.1.Q2_K.gguf’ saved [15644035008/15644035008]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE9heykddUQb",
        "outputId": "67a013e6-4f9d-458a-c019-affd070d8647"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.26.tar.gz (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.26-cp310-cp310-manylinux_2_35_x86_64.whl size=8129990 sha256=1ad651f3b247d332bf3313eebb3689fef5f4ce9830b6ca60459969a4cc5121cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/80/ce/ac6afea8c1d6fbcec7e14183033a5b2796c742d4f470010c72\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.2.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "import ctypes\n",
        "import json\n",
        "\n",
        "if model == 'mixtral-8x7b-instruct-v0.1.Q2_K':\n",
        "\tllm =Llama(model_path=\"/content/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\", n_gpu_layers=27, n_ctx=4096) # modify number of layers, dependent on RAM/GPU?\n",
        "  # !./server -m mixtral-8x7b-instruct-v0.1.Q2_K.gguf -ngl 27 -c 2048 --port 12345\n",
        "  # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF#example-llamacpp-command\n",
        "  # ./main -ngl 35 -m mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf --color -c 2048 --temp 0.7 --repeat_penalty 1.1 -n -1 -p \"[INST] {prompt} [/INST]\"\n",
        "\n",
        "elif model == 'openhermes-2-mistral-7b.Q5_K_M':\n",
        "  llm =Llama(model_path=\"/content/openhermes-2-mistral-7b.Q5_K_M.gguf\", n_gpu_layers=32, n_ctx=2048)\n",
        "  # https://huggingface.co/TheBloke/OpenHermes-2-Mistral-7B-GGUF#example-llamacpp-command\n",
        "  # ./main -ngl 32 -m openhermes-2-mistral-7b.Q4_K_M.gguf --color -c 2048 --temp 0.7 --repeat_penalty 1.1 -n -1 -p \"<|im_start|>system\\n{system_message}<|im_end|>\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\"\n",
        "\n",
        "elif model == 'dolphin-2.6-mixtral-8x7b.Q2_K':\n",
        "  llm =Llama(model_path=\"/content/dolphin-2.6-mixtral-8x7b.Q2_K.gguf\", n_gpu_layers=27, n_ctx=2048)\n",
        "\t#!./server -m dolphin-2.6-mixtral-8x7b.Q2_K.gguf -ngl 27 -c 2048 --port 12345\n",
        "\n",
        "elif model == 'mistral-7b-instruct-v0.2.Q8':\n",
        "  llm =Llama(model_path=\"/content/mistral-7b-instruct-v0.2.Q8.gguf\", n_gpu_layers=35)\n",
        "\t#!./server -m mistral-7b-instruct-v0.2.Q8_0.gguf -ngl 35 -c 0 --port 12345\n",
        "\n",
        "elif model == 'dolphin-2.2.1-mistral-7b.Q8':\n",
        "  llm =Llama(model_path=\"/content/dolphin-2.2.1-mistral-7b.Q8.gguf\", n_gpu_layers=35)\n",
        "\t#!./server -m dolphin-2.2.1-mistral-7b.Q8_0.gguf -ngl 35 -c 0 --port 12345\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnAJJh4vj_B6",
        "outputId": "2f8db9b5-ca0c-4a8b-c478-99adfbc56aa8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "prompt = \"Who are you?\"\n",
        "input_prompt = f\"\"\"[INST] <<SYS>>\n",
        "Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{prompt} [/INST]\"\"\"\n",
        "\n",
        "output = llm(input_prompt,max_tokens=1024)\n",
        "print(json.dumps(output, indent=2))\n",
        "print('\\n\\n')\n",
        "print(output[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5WxgrEfdocd",
        "outputId": "8d1a9775-576e-454e-979f-dfdc4ede2cd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-6e20497a-e786-4d7d-a235-85adf1145f22\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1704378105,\n",
            "  \"model\": \"/content/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \" I am an artificial intelligence model, designed to assist with tasks and provide information in a helpful and safe manner. My responses should not include harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. I strive to be socially unbiased and positive in my interactions.\\n\\nIf you ask something that doesn't make sense or isn't factually coherent, I will explain why instead of providing incorrect information. If I don't know the answer to a question, I will let you know.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 124,\n",
            "    \"completion_tokens\": 111,\n",
            "    \"total_tokens\": 235\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            " I am an artificial intelligence model, designed to assist with tasks and provide information in a helpful and safe manner. My responses should not include harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. I strive to be socially unbiased and positive in my interactions.\n",
            "\n",
            "If you ask something that doesn't make sense or isn't factually coherent, I will explain why instead of providing incorrect information. If I don't know the answer to a question, I will let you know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "prompt = \"Generate lyrics for a romantic love song\"\n",
        "input_prompt = f\"\"\"[INST] <<SYS>>\n",
        "You are a charismatics, talented, respectful and honest musician. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{prompt} [/INST]\"\"\"\n",
        "\n",
        "output = llm(input_prompt,max_tokens=1024)\n",
        "print(json.dumps(output, indent=2))\n",
        "print('\\n\\n')\n",
        "print(output[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2HD2gcil-G3",
        "outputId": "d50b4797-e789-4b8f-9e24-849ec4f48c60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-7e21dfff-213e-4093-964f-b8cd68a24d19\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1704378182,\n",
            "  \"model\": \"/content/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \" Verse 1:\\nI see your face in all my dreams, every single night\\nYour smile is like a ray of sunshine bringing me light\\nI love the way you look at me and how we click\\nIt's your touch that makes my heart tick\\n\\nChorus:\\nYou are my everything, my soulmate and my queen\\nWithout you I feel incomplete, like I am lost at sea\\nYour voice is music to my ears, your kisses are like a sweet dream\\nI can't imagine my life without you, baby you're the one for me\\n\\nVerse 2:\\nThe way you move and how you dance\\nCan make even a cold man give romance a chance\\nWe were just friends but now you're more than that\\nYou complete every part of me; it's crazy, but fact\\n\\nChorus:\\nYou are my everything, my soulmate and my queen\\nWithout you I feel incomplete, like I am lost at sea\\nYour voice is music to my ears, your kisses are like a sweet dream\\nI can't imagine my life without you, baby you're the one for me\\n\\nBridge:\\nYou make me laugh; you make me feel alive\\nJust being around you makes everything fine\\nI love the way we talk and how our minds think alike\\nWe were just two souls but now we're a perfect fit\\n\\nChorus:\\nYou are my everything, my soulmate and my queen\\nWithout you I feel incomplete, like I am lost at sea\\nYour voice is music to my ears, your kisses are like a sweet dream\\nI can't imagine my life without you, baby you're the one for me\\n\\nOutro:\\nWe were just two but now we're one perfect duo,\\nEnjoying every moment of our love-filled journey.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 142,\n",
            "    \"completion_tokens\": 395,\n",
            "    \"total_tokens\": 537\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            " Verse 1:\n",
            "I see your face in all my dreams, every single night\n",
            "Your smile is like a ray of sunshine bringing me light\n",
            "I love the way you look at me and how we click\n",
            "It's your touch that makes my heart tick\n",
            "\n",
            "Chorus:\n",
            "You are my everything, my soulmate and my queen\n",
            "Without you I feel incomplete, like I am lost at sea\n",
            "Your voice is music to my ears, your kisses are like a sweet dream\n",
            "I can't imagine my life without you, baby you're the one for me\n",
            "\n",
            "Verse 2:\n",
            "The way you move and how you dance\n",
            "Can make even a cold man give romance a chance\n",
            "We were just friends but now you're more than that\n",
            "You complete every part of me; it's crazy, but fact\n",
            "\n",
            "Chorus:\n",
            "You are my everything, my soulmate and my queen\n",
            "Without you I feel incomplete, like I am lost at sea\n",
            "Your voice is music to my ears, your kisses are like a sweet dream\n",
            "I can't imagine my life without you, baby you're the one for me\n",
            "\n",
            "Bridge:\n",
            "You make me laugh; you make me feel alive\n",
            "Just being around you makes everything fine\n",
            "I love the way we talk and how our minds think alike\n",
            "We were just two souls but now we're a perfect fit\n",
            "\n",
            "Chorus:\n",
            "You are my everything, my soulmate and my queen\n",
            "Without you I feel incomplete, like I am lost at sea\n",
            "Your voice is music to my ears, your kisses are like a sweet dream\n",
            "I can't imagine my life without you, baby you're the one for me\n",
            "\n",
            "Outro:\n",
            "We were just two but now we're one perfect duo,\n",
            "Enjoying every moment of our love-filled journey.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Wie hoch ist die Versicherungssumme? Antworte mit folgendem JSON-Schema: {\"Versicherungssumme\": \"100000\", \"Versicherungsnehmer_Name\": \"Testfirma GmbH\", \"Versicherungsnehmer_Anschrift\": \"Musterstr. 10, 10000 Berlin\", \"Versicherungsnehmer_Branche\": \"Textilproduktion\", \"Versicherungsnehmer_Umsatz\": \"23000000\", \"Vorschäden_benannt\": \"Ja, in 2019 gab es einen Schaden mit folgenden Details\"}. Formatiere Zahlen ohne Tausender-Trennzeichen.\n",
        " Der Kontext ist die Email  inklusive mehrerer Anhänge eines Versicherungsmaklers, die die Anfrage für eine D&O-Versicherung seines Kunden enthält:\n",
        "\n",
        "# Email Nachricht:\n",
        "\n",
        "From: Ralf Löffler - Universal Insurance <r.loeffler@universal-insurance.com>\n",
        "Sent: Wed, 04 Oct 2023 16:43:22 +0200\n",
        "To: \"Kloeppel; Rolf\" <rolf.kloeppel@meiermakler.de>\n",
        "Cc: Rolf van de Sand - Universal Insurance <m.vandesand@universal-insurance.com>\n",
        "Subject: Quotierungsanfrage zur D&O-Versicherung, VN: Zorrsen Beteiligungsgesellschaft mbH\n",
        "-----------------\n",
        "\n",
        "Hallo Herr Kloeppel,\n",
        "\n",
        "wir hoffen, Sie hatten einen angenehmen Feiertag.\n",
        "\n",
        "Zu unserer besteMeiermen Kundenverbindung Zorrsen Beteiligungsgesellschaft mbH bitten wir um Ihre Quotierung zur D&O-Versicherung per 01.01.2024.\n",
        "\n",
        "Die aktuelle Versicherungssumme beträgt 5,5 Mio. € zu einer Jahresprämie in Höhe von 7.920 € netto.\n",
        "Der Umsatz im letzten Jahr betrug 78,5 Millionen EUR.\n",
        "\n",
        "Beigefügt erhalten Sie die bisherigen Vertragsunterlagen sowie ein Organigramm. Versichert werden soll die Zorrsen Beteiligungsgesellschaft mbH als VN und die darunterliegenden Tochtergesellschaften (gelb markiert).\n",
        "\n",
        "Es gibt einen laufenden D&O-Schadensfall aufgrund einer Inanspruchnahme eines ehemaligen Geschäftsführers, welcher im Jahr 2017 entlassen wurde. Ihm wird vorgeworfen, für ein damaliges Bauvorhaben das Budget deutlich überzogen zu haben.\n",
        "\n",
        "Für Ihre Rückmeldung vielen Dank im Voraus.\n",
        "\n",
        "Mit besten Grüßen\n",
        "\n",
        "Ralf Löffler\n",
        "Kundenbetreuer Industrie\n",
        "\n",
        "T +49 99 190189-18\n",
        "r.loeffler@universal-insurance.com <mailto:r.loeffler@universal-insurance.com>\n",
        "\n",
        "Sicherer Dokumentenversand\n",
        "Ab sofort können Sie uns Ihre Dokumente auch direkt verschlüsselt vom PC & Smartphone über https://www.sicherer-dokumentenversand.de <https://www.sicherer-dokumentenversand.de/>  zukommen lassen.\n",
        "\n",
        "Universal Insurance Versicherungsmakler GmbH\n",
        "Karola-Trutschenko-Platz 2 · 20700 Potsdam\n",
        "\n",
        "\n",
        "\n",
        "www.universal-insurance.com <https://www.universal-insurance.com/impressum>\n",
        "\n",
        "Unternehmenssitz: Karola-Trutschenko-Platz 2 · 20700 Potsdam\n",
        "Handelsregister: Amtsgericht Potsdam · HRB 32397\n",
        "Geschäftsführer: Lutz Lorentzen, Klaas Lollmund, Lutz Ummsen, Hans Berentz, Lorentz H. Gronken, Kai Gronken\n",
        "Beirat: Lutz Transitz, Prof. Ottmar Halonkeli, Lorentz P. Loppelbaum\n",
        "\n",
        "Als Versicherungsmakler sind wir nach § 34 d Abs. 1 der Gewerbeordnung tätig und im Vermittlungsregister unter der Registernummer D-KJHG-U7HH-77 eingetragen.\n",
        "\n",
        "Wir sind klimaneutral! Gerne informieren wir Sie über unsere aktuellen Klimaschutzprojekte.\n",
        "\n",
        " <https://www.universal-insurance.com/nachhaltigkeit>      <https://www.linkedin.com/company/global-gruppe-linkedin>    <https://www.xing.com/pages/universalinsurance>   ·   Datenschutzhinweise <https://www.universal-insurance.com/datenschutzerklaerung>    ·   Impressum <https://www.universal-insurance.com/impressum>\n",
        "\n",
        "Diese E-Mail enthält vertrauliche und/oder rechtlich geschützte Informationen. Wenn Sie nicht der richtige Adressat sind oder diese E-Mail irrtümlich erhalten haben, informieren Sie bitte sofort den Absender und vernichten Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet.\n",
        "\n",
        "This email may contain confidential and/or privileged information. If you are not the intended recipient (or have received this email in error) please notify the sender immediately and destroy this email. Any unauthorized copying, disclosure or distribution of the material in this email is strictly forbidden.\n",
        "\n",
        "Ralf Löffler\n",
        "Kundenbetreuer Industrie\n",
        "\n",
        "T +49 99 190189-18\n",
        "r.loeffler@universal-insurance.com <mailto:r.loeffler@universal-insurance.com>\n",
        "Karola-Trutschenko-Platz 2 · 20700 Potsdam\n",
        "\n",
        "\n",
        "\n",
        "Handelsregister: Amtsgericht Potsdam · HRB 32397\n",
        "Geschäftsführer: Lutz Lorentzen, Klaas Lollmund, Lutz Ummsen, Hans Berentz, Lorentz H. Gronken, Kai Gronken\n",
        "Beirat: Lutz Transitz, Prof. Ottmar Halonkeli, Lorentz P. Loppelbaum\n",
        "Unternehmenssitz: Karola-Trutschenko-Platz 2 · 20700 Potsdam\n",
        "\n",
        "\n",
        "Als Versicherungsmakler sind wir nach § 34 d Abs. 1 der Gewerbeordnung tätig und im Vermittlungsregister unter der Registernummer D-KJHG-U7HH-77 eingetragen.\n",
        "\n",
        "Sicherer Dokumentenversand\n",
        "Ab sofort können Sie uns Ihre Dokumente auch direkt verschlüsselt vom PC & Smartphone über https://www.sicherer-dokumentenversand.de <https://www.sicherer-dokumentenversand.de>  zukommen lassen.\n",
        "\n",
        "\n",
        " <https://signatur.universal-insurance.com/public/global-gruppe.png> \t <https://www.linkedin.com/company/global-gruppe-linkedin>       <https://www.xing.com/pages/universalinsurance>       <https://www.universal-insurance.com/nachhaltigkeit>  \t <https://signatur.universal-insurance.com/public/wiwo_badge.png>\n",
        "\n",
        "Datenschutz <https://www.universal-insurance.com/datenschutzerklaerung>    •   Impressum <https://www.universal-insurance.com/impressum>\n",
        "Diese E-Mail enthält vertrauliche und/oder rechtlich geschützte Informationen. Wenn Sie nicht der richtige Adressat sind oder diese E-Mail irrtümlich erhalten haben, informieren Sie bitte sofort den Absender und vernichten Sie diese E-Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet.\n",
        "\n",
        "This email may contain confidential and/or privileged information. If you are not the intended recipient (or have received this email in error) please notify the sender immediately and destroy this email. Any unauthorized copying, disclosure or distribution of the material in this email is strictly forbidden.\n",
        "\n",
        "# Organigramm:\n",
        "\n",
        "Zorrsen AG\n",
        "Schweiz\n",
        "\n",
        "Zorrsen\n",
        "Investment AG\n",
        "Schweiz\n",
        "\n",
        "Zorrsen Beteilig-\n",
        "ungsges. GmbH\n",
        "Deutschland\n",
        "\n",
        "Zorrsen\n",
        "Holding GmbH\n",
        "Deutschland\n",
        "\n",
        "Testcompany\n",
        "Menneprom GmbH\n",
        "Deutschland\n",
        "\n",
        "Hummsen\n",
        "Lackfabrik GmbH\n",
        "Deutschland\n",
        "\n",
        "\n",
        "# Versicherungsschein:\n",
        "Versicherungsschein\n",
        "\n",
        "BBB D&O-Versicherung 098765\n",
        "\n",
        "Versicherungsnehmer/in\n",
        "\n",
        "Zorrsen Beteiligungsgesellschaft mbH Juliusweg 9 28374 Zutzenhausen\n",
        "\n",
        "Tätigkeitsbereich\n",
        "\n",
        "Produktion von Aluminium-Großarmaturen\n",
        "\n",
        "Versicherungsvermittler\n",
        "\n",
        "Universal Insurance Versicherungsmakler GmbH Karola-Trutschenko-Platz 2 20700 Potsdam\n",
        "\n",
        "Versicherungsschein-Nr.\n",
        "\n",
        "748344 (alt: 43789434)\n",
        "\n",
        "Vertragsdaten\n",
        "\n",
        "Vertragsbeginn:\n",
        "\n",
        "Beginn aktuelle Versicherungsperiode: Ablauf aktuelle Versicherungsperiode:\n",
        "\n",
        "Versicherungssumme\n",
        "\n",
        "€ 5.500.000,00\n",
        "\n",
        "Versicherungsprämie\n",
        "\n",
        "21.33.2012 12:00 Uhr\n",
        "\n",
        "01.01.2023 12:00 Uhr\n",
        "\n",
        "01.01.2024 12:00 Uhr\n",
        "\n",
        "Die Versicherungsprämie beträgt € 9.900,00 pro Versicherungsjahr (zuzüglich Versicherungsteuer).\n",
        "\n",
        "Den insgesamt für die o.g. Versicherungsperiode zu zahlenden Versicherungsbeitrag entnehmen Sie bitte der zu diesem Versicherungsschein gesondert erstellten Beitragsrechnung.\n",
        "\n",
        "Gemäß § 7 Abs. 4 VersStG ist der unten genannte führende Versicherer von den übrigen beteiligten Versicherern der BBB Insurance bestimmt, die Versicherungsteuer auch für diese zu entrichten.\n",
        "\n",
        "BBB Insurance GmbH | www.bbb.eu | info@bbb.eu Geschäftsführer: Johann Ronser | Sitz der Gesellschaft: Potsdam | AG Potsdam HRB 87654 | St.-Nr. 215/6500/0604 | USt.-ID-Nr. DE 473894 Hauptsitz Potsdam | Im Hafenbau 5 | 50670 Potsdam | T +49 99 473894-0 | F +49 99 473894-25 Standort Potsdam | Amselweg 48-50 | 20459 Potsdam | T +49 99 473894-20 | F +49 99 473894-49 Seite 2 von 8 | BBB-Nr.;: 098765\n",
        "\n",
        "Vertragsbestimmungen\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Nachtrag\n",
        "Nachtrag Nr. 1 zum Versicherungsschein vom 24.33.2022\n",
        "\n",
        "BBB D&O-Versicherung 098765\n",
        "\n",
        "Versicherungsnehmer/in\n",
        "\n",
        "Zorrsen Beteiligungsgesellschaft mbH Juliusweg 9 28374 Zutzenhausen\n",
        "\n",
        "Versicherungsvermittler\n",
        "\n",
        "Universal Insurance Versicherungsmakler GmbH Karola-Trutschenko-Platz 2 20700 Potsdam\n",
        "\n",
        "Versicherungsschein-Nr.\n",
        "\n",
        "748344 (alt: 43789434)\n",
        "\n",
        "Änderungsdatum\n",
        "\n",
        "01.01.2023\n",
        "\n",
        "Änderungsgründe\n",
        "\n",
        "› ›\n",
        "\n",
        "Nettoisierung der Versicherungsprämie Aufnahme der Besonderen Vereinbarung „Nettoisierung“\n",
        "\n",
        "Der Versicherungsschein in der Fassung vom 24.33.2022 wird wie folgt geändert:\n",
        "\n",
        "Versicherungsprämie\n",
        "\n",
        "Die Versicherungsprämie beträgt € 7.920,00 pro Versicherungsjahr (zuzüglich Versicherungsteuer).\n",
        "\n",
        "Den zu zahlenden Versicherungsbeitrag entnehmen Sie bitte der zu diesem Nachtrag gesondert erstellten Beitragsrechnung.\n",
        "\n",
        "Gemäß § 7 Abs. 4 VersStG ist der führende Versicherer von den übrigen beteiligten Versicherern der BBB Insurance bestimmt, die Versicherungsteuer auch für diese zu entrichten.\n",
        "\n",
        "BBB Insurance GmbH | www.bbb.eu | info@bbb.eu Geschäftsführer: Johann Ronser | Sitz der Gesellschaft: Potsdam | AG Potsdam HRB 87654 | St.-Nr. 215/6500/0604 | USt.-ID-Nr. DE 473894 Hauptsitz Potsdam | Im Hafenbau 5 | 50670 Potsdam | T +49 99 473894-0 | F +49 99 473894-25 Standort Potsdam | Amselweg 48-50 | 20459 Potsdam | T +49 99 473894-20 | F +49 99 473894-49 Seite 2 von 5\n",
        "\n",
        "\n",
        "\n",
        "# Versicherungsbedingungen\n",
        "AVB-BBB 5.0\n",
        "\n",
        "Allgemeine Bedingungen zur BBB D&O-Versicherung\n",
        "\n",
        "Hinweis:\n",
        "\n",
        "Aus Gründen der besseren Lesbarkeit wird auf die gleichzeitige Verwendung verschiedener geschlechtsspezifischer Sprachformen verzichtet. Sämtliche Personenbezeichnungen gelten gleichberechtigt für alle Geschlechter/Geschlechtsidentitäten.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "input_prompt = f\"\"\"[INST] <<SYS>>\n",
        "You are a professional data engineer. Your goal is to extract structured information from the user's input.\n",
        "<</SYS>>\n",
        "{prompt} [/INST]\"\"\"\n",
        "\n",
        "output = llm(input_prompt,max_tokens=512)\n",
        "print(json.dumps(output, indent=2))\n",
        "print('\\n\\n')\n",
        "print(output[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "LXLXj9iRr3me",
        "outputId": "fcde20cf-0c6e-463e-ed90-9c47d383cfba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Approach: Mixtral-8x7B-Instruct via llama.cpp and webserver\n",
        "\n",
        "**=> access to webserver not working!**\n",
        "\n",
        "- 4 token / second\n",
        "- It takes about 10 minutes for everything to be setup, downloaded and loaded.\n",
        "- Wait until the inference cell outputs \"llama server listening at... all slots are idle and system prompt is empty, clear the KV cache.\" Use the URL from the output of the previous cell that says \"Connect using the following address when the server is up.\"\n",
        "\n",
        "Uses llama.cpp https://github.com/ggerganov/llama.cpp\n",
        "\n",
        "Source: https://www.reddit.com/r/LocalLLaMA/comments/18ggkp6/mixtral8x7binstruct_on_free_colab_slow_4ts_but/"
      ],
      "metadata": {
        "id": "xJvJnJXMWOAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Choose a Model\n",
        "model = 'mixtral-8x7b-instruct-v0.1.Q2_K' #@param ['mixtral-8x7b-instruct-v0.1.Q2_K', 'dolphin-2.6-mixtral-8x7b.Q2_K', 'mistral-7b-instruct-v0.2.Q8', 'dolphin-2.2.1-mistral-7b.Q8']\n"
      ],
      "metadata": {
        "id": "Ego9Ohb6RwNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88WyLLrDBe-o"
      },
      "outputs": [],
      "source": [
        "#@title #Runtime Info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emySi6TEC-M8"
      },
      "outputs": [],
      "source": [
        "#@title # Setup\n",
        "\n",
        "# takes approx. 5 minutes\n",
        "\n",
        "%cd /content/\n",
        "!rm -rf llama.cpp\n",
        "!git clone --depth 1 https://github.com/ggerganov/llama.cpp.git\n",
        "%cd llama.cpp\n",
        "!make LLAMA_CUBLAS=1\n",
        "\n",
        "if model == 'mixtral-8x7b-instruct-v0.1.Q2_K':\n",
        "\t!wget https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\n",
        "elif model == 'dolphin-2.6-mixtral-8x7b.Q2_K':\n",
        "\t!wget https://huggingface.co/TheBloke/dolphin-2.6-mixtral-8x7b-GGUF/resolve/main/dolphin-2.6-mixtral-8x7b.Q2_K.gguf\n",
        "elif model == 'mistral-7b-instruct-v0.2.Q8':\n",
        "\t!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q8_0.gguf\n",
        "elif model == 'dolphin-2.2.1-mistral-7b.Q8':\n",
        "\t!wget https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF/resolve/main/dolphin-2.2.1-mistral-7b.Q8_0.gguf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Connect using the following address when the server is up.\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(12345)\"))"
      ],
      "metadata": {
        "id": "kxPwlxke3WSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # inference\n",
        "%cd /content/llama.cpp\n",
        "if model == 'mixtral-8x7b-instruct-v0.1.Q2_K':\n",
        "\t!./server -m mixtral-8x7b-instruct-v0.1.Q2_K.gguf -ngl 27 -c 2048 --port 12345\n",
        "elif model == 'dolphin-2.6-mixtral-8x7b.Q2_K':\n",
        "\t!./server -m dolphin-2.6-mixtral-8x7b.Q2_K.gguf -ngl 27 -c 2048 --port 12345\n",
        "elif model == 'mistral-7b-instruct-v0.2.Q8':\n",
        "\t!./server -m mistral-7b-instruct-v0.2.Q8_0.gguf -ngl 35 -c 0 --port 12345\n",
        "elif model == 'dolphin-2.2.1-mistral-7b.Q8':\n",
        "\t!./server -m dolphin-2.2.1-mistral-7b.Q8_0.gguf -ngl 35 -c 0 --port 12345\n",
        "\n"
      ],
      "metadata": {
        "id": "q9IV1xQao-We"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}